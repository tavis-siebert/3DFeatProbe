### Config for VGGT retrain experiment
defaults:
  - machine: local
  - model: vggt
  - training: default
  - dataset: multi_dataset
  - __self__

# -- Training
training:
  optim:
    optimizer:
      optimizer_config:
        lr: 5e-5
    schedulers:
      lr:
        name: CompositeParamScheduler
        scheduler_config:
          schedulers:
            - name: LinearParamScheduler
              scheduler_config:
                start_value: 1e-8
                end_value: 5e-5
            - name: CosineParamScheduler
              scheduler_config:
                start_value: 5e-5
                end_value: 1e-8
          lengths: [0.05, 0.95]
          interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        name: ConstantParamScheduler
        scheduler_config:
          value: 0.05
    gradient_clip:
      module_configs:
      - module_name: ["aggregator"]
        max_norm: 1.0   
        norm_type: 2
      - module_name: ["depth"]
        max_norm: 1.0   
        norm_type: 2
      - module_name: ["camera"]
        max_norm: 1.0   
        norm_type: 2
    frozen_submodules:
      - "aggregator.patch_embed"
  logging:
    metrics_to_log:
      train:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth
      val:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth
  checkpoint:
    resume_checkpoint_path: ???
  loss:
    loss_fn: "MultitaskLoss"
    loss_config:
      camera:
        weight: 5.0
        loss_type: "l1"
      depth:
        weight: 1.0
        gradient_loss_fn: "grad" 
        valid_range: 0.98
      point: null
  distributed:
    ddp_args:
      find_unused_parameters: False
      gradient_as_bucket_view: True  # Less memory used
      bucket_cap_mb: 25
      broadcast_buffers: True

# -- Model
model:
  model_config:
    pretrained_patch_embed_path: ???
    embed_dim: 768
    enable_point: false
    enable_track: false
    aggregator_config: ???
    camera_head_config: ???
    depth_head_config: ???

# Wandb
wandb:
  project: ???
  entity: ???

# Paths for convenience
root_data_dir: ${machine.root_data_dir}
mapanything_metadata_dir: ${machine.mapanything_metadata_dir}
checkpoints_dir: ${machine.checkpoints_dir}
logging_dir: ${machine.logging_dir}